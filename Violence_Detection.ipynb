{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Voilence Detection.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jwlkj_T8oipy",
        "outputId": "81300242-171f-42c9-8495-b3c4d96bfb2f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ar1jkJJxdzp-"
      },
      "source": [
        "Importing Libararies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNEyNJrWtU4n"
      },
      "source": [
        "def warn(*args, **kwargs):\n",
        "    pass\n",
        "import warnings\n",
        "warnings.warn = warn\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from tqdm import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjHVW6d5xYdP"
      },
      "source": [
        "from tensorflow import keras as keras\n",
        "from keras.models import Sequential, Input, Model\n",
        "from keras.layers import Dense, Flatten, Conv3D, MaxPooling3D, Dropout, BatchNormalization, Activation, LeakyReLU, Add, Multiply\n",
        "from keras.regularizers import l2\n",
        "from keras.layers.core import Lambda\n",
        "from keras.utils import np_utils\n",
        "from keras.utils import Sequence\n",
        "from keras.optimizers import Adam, SGD"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b99k-9AQd7bW"
      },
      "source": [
        "Convert Video into Numpy Arrays"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KN22z9q9uJQP"
      },
      "source": [
        "def getOpticalFlow(video):\n",
        "    gray_video = []\n",
        "    for i in range(len(video)):\n",
        "        img = cv2.cvtColor(video[i], cv2.COLOR_RGB2GRAY)\n",
        "        gray_video.append(np.reshape(img,(224,224,1)))\n",
        "\n",
        "    flows = []\n",
        "    for i in range(0,len(video)-1):\n",
        "        flow = cv2.calcOpticalFlowFarneback(gray_video[i], gray_video[i+1], None, 0.5, 3, 15, 3, 5, 1.2, cv2.OPTFLOW_FARNEBACK_GAUSSIAN)\n",
        "        flow[..., 0] -= np.mean(flow[..., 0])\n",
        "        flow[..., 1] -= np.mean(flow[..., 1])\n",
        "        flow[..., 0] = cv2.normalize(flow[..., 0],None,0,255,cv2.NORM_MINMAX)\n",
        "        flow[..., 1] = cv2.normalize(flow[..., 1],None,0,255,cv2.NORM_MINMAX)\n",
        "        flows.append(flow)\n",
        "    flows.append(np.zeros((224,224,2)))\n",
        "    return np.array(flows, dtype=np.float32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efU0hW2_uSae"
      },
      "source": [
        "def Video2Npy(file_path, resize=(224,224)):\n",
        "    cap = cv2.VideoCapture(file_path)\n",
        "    len_frames = int(cap.get(7))\n",
        "    try:\n",
        "        frames = []\n",
        "        for i in range(len_frames-1):\n",
        "            _, frame = cap.read()\n",
        "            frame = cv2.resize(frame,resize, interpolation=cv2.INTER_AREA)\n",
        "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "            frame = np.reshape(frame, (224,224,3))\n",
        "            frames.append(frame)   \n",
        "    except:\n",
        "        print(\"Error: \", file_path, len_frames,i)\n",
        "    finally:\n",
        "        frames = np.array(frames)\n",
        "        cap.release()\n",
        "            \n",
        "    # Get the optical flow of video\n",
        "    flows = getOpticalFlow(frames)\n",
        "    \n",
        "    result = np.zeros((len(flows),224,224,5))\n",
        "    result[...,:3] = frames\n",
        "    result[...,3:] = flows\n",
        "    \n",
        "    return result\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yx7-neeHuUx-"
      },
      "source": [
        "def Save2Npy(file_dir, save_dir):\n",
        "    if not os.path.exists(save_dir):\n",
        "        os.makedirs(save_dir)\n",
        "    videos = os.listdir(file_dir)\n",
        "    for v in tqdm(videos):\n",
        "        video_name = v.split('.')[0]\n",
        "        video_path = os.path.join(file_dir, v)\n",
        "        save_path = os.path.join(save_dir, video_name+'.npy') \n",
        "        # Load and preprocess video\n",
        "        data = Video2Npy(file_path=video_path, resize=(224,224))\n",
        "        data = np.uint8(data)\n",
        "        np.save(save_path, data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljOxO9mFeH7o"
      },
      "source": [
        "Preprocessing(Data Augmentation) and Generate batches of the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHzA2G-kuWZN"
      },
      "source": [
        "class DataGenerator(Sequence):\n",
        "    def __init__(self, directory, batch_size=1, shuffle=True, data_augmentation=True):\n",
        "        self.batch_size = batch_size\n",
        "        self.directory = directory\n",
        "        self.shuffle = shuffle\n",
        "        self.data_aug = data_augmentation\n",
        "        self.X_path, self.Y_dict = self.search_data() \n",
        "        self.print_stats()\n",
        "        return None\n",
        "        \n",
        "    def search_data(self):\n",
        "        X_path = []\n",
        "        Y_dict = {}\n",
        "        # list all kinds of sub-folders\n",
        "        self.dirs = sorted(os.listdir(self.directory))\n",
        "        one_hots = np_utils.to_categorical(range(len(self.dirs)))\n",
        "        for i,folder in enumerate(self.dirs):\n",
        "            folder_path = os.path.join(self.directory,folder)\n",
        "            for file in os.listdir(folder_path):\n",
        "                file_path = os.path.join(folder_path,file)\n",
        "                # append the each file path, and keep its label  \n",
        "                X_path.append(file_path)\n",
        "                Y_dict[file_path] = one_hots[i]\n",
        "        return X_path, Y_dict\n",
        "    \n",
        "    def print_stats(self):\n",
        "        # calculate basic information\n",
        "        self.n_files = len(self.X_path)\n",
        "        self.n_classes = len(self.dirs)\n",
        "        self.indexes = np.arange(len(self.X_path))\n",
        "        np.random.shuffle(self.indexes)\n",
        "        # Output states\n",
        "        print(\"Found {} files belonging to {} classes.\".format(self.n_files,self.n_classes))\n",
        "        for i,label in enumerate(self.dirs):\n",
        "            print('%10s : '%(label),i)\n",
        "        return None\n",
        "    \n",
        "    def __len__(self):\n",
        "        # calculate the iterations of each epoch\n",
        "        steps_per_epoch = np.ceil(len(self.X_path) / float(self.batch_size))\n",
        "        return int(steps_per_epoch)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # get the indexs of each batch\n",
        "        batch_indexs = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
        "        # using batch_indexs to get path of current batch\n",
        "        batch_path = [self.X_path[k] for k in batch_indexs]\n",
        "        # get batch data\n",
        "        batch_x, batch_y = self.data_generation(batch_path)\n",
        "        return batch_x, batch_y\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        # shuffle the data at each end of epoch\n",
        "        if self.shuffle == True:\n",
        "            np.random.shuffle(self.indexes)\n",
        "\n",
        "    def data_generation(self, batch_path):\n",
        "        # load data into memory, you can change the np.load to any method you want\n",
        "        batch_x = [self.load_data(x) for x in batch_path]\n",
        "        batch_y = [self.Y_dict[x] for x in batch_path]\n",
        "        # transfer the data format and take one-hot coding for labels\n",
        "        batch_x = np.array(batch_x)\n",
        "        batch_y = np.array(batch_y)\n",
        "        return batch_x, batch_y\n",
        "      \n",
        "    def normalize(self, data):\n",
        "        mean = np.mean(data)\n",
        "        std = np.std(data)\n",
        "        return (data-mean) / std\n",
        "    \n",
        "    def random_flip(self, video, prob):\n",
        "        s = np.random.rand()\n",
        "        if s < prob:\n",
        "            video = np.flip(m=video, axis=2)\n",
        "        return video    \n",
        "    \n",
        "    def uniform_sampling(self, video, target_frames=64):\n",
        "        # get total frames of input video and calculate sampling interval \n",
        "        len_frames = int(len(video))\n",
        "        interval = int(np.ceil(len_frames/target_frames))\n",
        "        # init empty list for sampled video and \n",
        "        sampled_video = []\n",
        "        for i in range(0,len_frames,interval):\n",
        "            sampled_video.append(video[i])     \n",
        "        # calculate numer of padded frames and fix it \n",
        "        num_pad = target_frames - len(sampled_video)\n",
        "        padding = []\n",
        "        if num_pad>0:\n",
        "            for i in range(-num_pad,0):\n",
        "                try: \n",
        "                    padding.append(video[i])\n",
        "                except:\n",
        "                    padding.append(video[0])\n",
        "            sampled_video += padding     \n",
        "        # get sampled video\n",
        "        return np.array(sampled_video, dtype=np.float32)\n",
        "    \n",
        "    def random_clip(self, video, target_frames=64):\n",
        "        start_point = np.random.randint(len(video)-target_frames)\n",
        "        return video[start_point:start_point+target_frames]\n",
        "    \n",
        "    def dynamic_crop(self, video):\n",
        "        # extract layer of optical flow from video\n",
        "        opt_flows = video[...,3]\n",
        "        # sum of optical flow magnitude of individual frame\n",
        "        magnitude = np.sum(opt_flows, axis=0)\n",
        "        # filter slight noise by threshold \n",
        "        thresh = np.mean(magnitude)\n",
        "        magnitude[magnitude<thresh] = 0\n",
        "        # calculate center of gravity of magnitude map and adding 0.001 to avoid empty value\n",
        "        x_pdf = np.sum(magnitude, axis=1) + 0.001\n",
        "        y_pdf = np.sum(magnitude, axis=0) + 0.001\n",
        "        # normalize PDF of x and y so that the sum of probs = 1\n",
        "        x_pdf /= np.sum(x_pdf)\n",
        "        y_pdf /= np.sum(y_pdf)\n",
        "        # randomly choose some candidates for x and y \n",
        "        x_points = np.random.choice(a=np.arange(224), size=10, replace=True, p=x_pdf)\n",
        "        y_points = np.random.choice(a=np.arange(224), size=10, replace=True, p=y_pdf)\n",
        "        # get the mean of x and y coordinates for better robustness\n",
        "        x = int(np.mean(x_points))\n",
        "        y = int(np.mean(y_points))\n",
        "        # avoid to beyond boundaries of array\n",
        "        x = max(56,min(x,167))\n",
        "        y = max(56,min(y,167))\n",
        "        # get cropped video \n",
        "        return video[:,x-56:x+56,y-56:y+56,:]  \n",
        "    \n",
        "    def color_jitter(self,video):\n",
        "        # range of s-component: 0-1\n",
        "        # range of v component: 0-255\n",
        "        s_jitter = np.random.uniform(-0.2,0.2)\n",
        "        v_jitter = np.random.uniform(-30,30)\n",
        "        for i in range(len(video)):\n",
        "            hsv = cv2.cvtColor(video[i], cv2.COLOR_RGB2HSV)\n",
        "            s = hsv[...,1] + s_jitter\n",
        "            v = hsv[...,2] + v_jitter\n",
        "            s[s<0] = 0\n",
        "            s[s>1] = 1\n",
        "            v[v<0] = 0\n",
        "            v[v>255] = 255\n",
        "            hsv[...,1] = s\n",
        "            hsv[...,2] = v\n",
        "            video[i] = cv2.cvtColor(hsv, cv2.COLOR_HSV2RGB)\n",
        "        return video\n",
        "        \n",
        "    def load_data(self, path):\n",
        "        # load the processed .npy files which have 5 channels (1-3 for RGB, 4-5 for optical flows)\n",
        "        data = np.load(path, mmap_mode='r')\n",
        "        data = np.float32(data)\n",
        "        # sampling 64 frames uniformly from the entire video\n",
        "        data = self.uniform_sampling(video=data, target_frames=64)\n",
        "        # whether to utilize the data augmentation\n",
        "        if  self.data_aug:\n",
        "            data[...,:3] = self.color_jitter(data[...,:3])\n",
        "            data = self.random_flip(data, prob=0.5)\n",
        "        # normalize rgb images and optical flows, respectively\n",
        "        data[...,:3] = self.normalize(data[...,:3])\n",
        "        data[...,3:] = self.normalize(data[...,3:])\n",
        "        return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQe1sBh1eYCm"
      },
      "source": [
        "Making Optical Flow Gated Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UgohcbthuXwT"
      },
      "source": [
        "# extract the rgb images \n",
        "def get_rgb(input_x):\n",
        "    rgb = input_x[...,:3]\n",
        "    return rgb\n",
        "\n",
        "# extract the optical flows\n",
        "def get_opt(input_x):\n",
        "    opt= input_x[...,3:5]\n",
        "    return opt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zYorXcnzuZOW",
        "outputId": "eafc640b-8f1d-4484-e96b-97830decbee3"
      },
      "source": [
        "inputs = Input(shape=(64,224,224,5))\n",
        "\n",
        "rgb = Lambda(get_rgb,output_shape=None)(inputs)\n",
        "opt = Lambda(get_opt,output_shape=None)(inputs)\n",
        "\n",
        "##################################################### RGB channel #######################################################\n",
        "rgb = Conv3D(\n",
        "    16, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n",
        "rgb = Conv3D(\n",
        "    16, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n",
        "rgb = MaxPooling3D(pool_size=(1,2,2))(rgb)\n",
        "\n",
        "rgb = Conv3D(\n",
        "    16, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n",
        "rgb = Conv3D(\n",
        "    16, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n",
        "rgb = MaxPooling3D(pool_size=(1,2,2))(rgb)\n",
        "\n",
        "rgb = Conv3D(\n",
        "    32, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n",
        "rgb = Conv3D(\n",
        "    32, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n",
        "rgb = MaxPooling3D(pool_size=(1,2,2))(rgb)\n",
        "\n",
        "rgb = Conv3D(\n",
        "    32, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n",
        "rgb = Conv3D(\n",
        "    32, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n",
        "rgb = MaxPooling3D(pool_size=(1,2,2))(rgb)\n",
        "\n",
        "##################################################### Optical Flow channel ###########################################\n",
        "opt = Conv3D(\n",
        "    16, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(opt)\n",
        "opt = Conv3D(\n",
        "    16, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(opt)\n",
        "opt = MaxPooling3D(pool_size=(1,2,2))(opt)\n",
        "\n",
        "opt = Conv3D(\n",
        "    16, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(opt)\n",
        "opt = Conv3D(\n",
        "    16, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(opt)\n",
        "opt = MaxPooling3D(pool_size=(1,2,2))(opt)\n",
        "\n",
        "opt = Conv3D(\n",
        "    32, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(opt)\n",
        "opt = Conv3D(\n",
        "    32, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(opt)\n",
        "opt = MaxPooling3D(pool_size=(1,2,2))(opt)\n",
        "\n",
        "opt = Conv3D(\n",
        "    32, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='sigmoid', padding='same')(opt)\n",
        "opt = Conv3D(\n",
        "    32, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='sigmoid', padding='same')(opt)\n",
        "opt = MaxPooling3D(pool_size=(1,2,2))(opt)\n",
        "\n",
        "\n",
        "##################################################### Fusion and Pooling\n",
        "x = Multiply()([rgb,opt])\n",
        "x = MaxPooling3D(pool_size=(8,1,1))(x)\n",
        "\n",
        "##################################################### Merging Block\n",
        "x = Conv3D(\n",
        "    64, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(x)\n",
        "x = Conv3D(\n",
        "    64, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(x)\n",
        "x = MaxPooling3D(pool_size=(2,2,2))(x)\n",
        "\n",
        "x = Conv3D(\n",
        "    64, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(x)\n",
        "x = Conv3D(\n",
        "    64, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(x)\n",
        "x = MaxPooling3D(pool_size=(2,2,2))(x)\n",
        "\n",
        "x = Conv3D(\n",
        "    128, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(x)\n",
        "x = Conv3D(\n",
        "    128, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(x)\n",
        "x = MaxPooling3D(pool_size=(2,3,3))(x)\n",
        "\n",
        "##################################################### FC Layers ##################\n",
        "x = Flatten()(x)\n",
        "x = Dense(128,activation='relu')(x)\n",
        "x = Dropout(0.2)(x)\n",
        "x = Dense(32, activation='relu')(x)\n",
        "\n",
        "# Build the model\n",
        "pred = Dense(2, activation='softmax')(x)\n",
        "model = Model(inputs=inputs, outputs=pred)\n",
        "model.summary()\n",
        "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 64, 224, 224 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lambda_2 (Lambda)               (None, 64, 224, 224, 0           input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3 (Lambda)               (None, 64, 224, 224, 0           input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_22 (Conv3D)              (None, 64, 224, 224, 448         lambda_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_30 (Conv3D)              (None, 64, 224, 224, 304         lambda_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_23 (Conv3D)              (None, 64, 224, 224, 784         conv3d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_31 (Conv3D)              (None, 64, 224, 224, 784         conv3d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling3d_12 (MaxPooling3D) (None, 64, 112, 112, 0           conv3d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling3d_16 (MaxPooling3D) (None, 64, 112, 112, 0           conv3d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_24 (Conv3D)              (None, 64, 112, 112, 2320        max_pooling3d_12[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_32 (Conv3D)              (None, 64, 112, 112, 2320        max_pooling3d_16[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_25 (Conv3D)              (None, 64, 112, 112, 784         conv3d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_33 (Conv3D)              (None, 64, 112, 112, 784         conv3d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling3d_13 (MaxPooling3D) (None, 64, 56, 56, 1 0           conv3d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling3d_17 (MaxPooling3D) (None, 64, 56, 56, 1 0           conv3d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_26 (Conv3D)              (None, 64, 56, 56, 3 4640        max_pooling3d_13[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_34 (Conv3D)              (None, 64, 56, 56, 3 4640        max_pooling3d_17[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_27 (Conv3D)              (None, 64, 56, 56, 3 3104        conv3d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_35 (Conv3D)              (None, 64, 56, 56, 3 3104        conv3d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling3d_14 (MaxPooling3D) (None, 64, 28, 28, 3 0           conv3d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling3d_18 (MaxPooling3D) (None, 64, 28, 28, 3 0           conv3d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_28 (Conv3D)              (None, 64, 28, 28, 3 9248        max_pooling3d_14[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_36 (Conv3D)              (None, 64, 28, 28, 3 9248        max_pooling3d_18[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_29 (Conv3D)              (None, 64, 28, 28, 3 3104        conv3d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_37 (Conv3D)              (None, 64, 28, 28, 3 3104        conv3d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling3d_15 (MaxPooling3D) (None, 64, 14, 14, 3 0           conv3d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling3d_19 (MaxPooling3D) (None, 64, 14, 14, 3 0           conv3d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "multiply_1 (Multiply)           (None, 64, 14, 14, 3 0           max_pooling3d_15[0][0]           \n",
            "                                                                 max_pooling3d_19[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling3d_20 (MaxPooling3D) (None, 8, 14, 14, 32 0           multiply_1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_38 (Conv3D)              (None, 8, 14, 14, 64 18496       max_pooling3d_20[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_39 (Conv3D)              (None, 8, 14, 14, 64 12352       conv3d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling3d_21 (MaxPooling3D) (None, 4, 7, 7, 64)  0           conv3d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_40 (Conv3D)              (None, 4, 7, 7, 64)  36928       max_pooling3d_21[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_41 (Conv3D)              (None, 4, 7, 7, 64)  12352       conv3d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling3d_22 (MaxPooling3D) (None, 2, 3, 3, 64)  0           conv3d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_42 (Conv3D)              (None, 2, 3, 3, 128) 73856       max_pooling3d_22[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_43 (Conv3D)              (None, 2, 3, 3, 128) 49280       conv3d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling3d_23 (MaxPooling3D) (None, 1, 1, 1, 128) 0           conv3d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 128)          0           max_pooling3d_23[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 128)          16512       flatten_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 128)          0           dense_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 32)           4128        dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, 2)            66          dense_4[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 272,690\n",
            "Trainable params: 272,690\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4sIoEZsGuaYt"
      },
      "source": [
        "num_epochs  = 10\n",
        "batch_size  = 4\n",
        "workers = 16"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3V50_S2e78n"
      },
      "source": [
        "Loading The Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CFqHOPqKufVv",
        "outputId": "4c787424-9d3c-4acf-b064-d37219516335"
      },
      "source": [
        "train_generator = DataGenerator(directory='/content/drive/MyDrive/voilence/PreprocessedData/train', \n",
        "                                batch_size=batch_size, \n",
        "                                data_augmentation=True)\n",
        "\n",
        "val_generator = DataGenerator(directory='/content/drive/MyDrive/voilence/PreprocessedData/val',\n",
        "                              batch_size=batch_size, \n",
        "                              data_augmentation=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 800 files belonging to 2 classes.\n",
            "     Fight :  0\n",
            "  NonFight :  1\n",
            "Found 100 files belonging to 2 classes.\n",
            "     Fight :  0\n",
            "  NonFight :  1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3igPPWQfBzm"
      },
      "source": [
        "Training the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uVeNG6b1umCI",
        "outputId": "55e549ae-f3b2-4cc9-bf14-bb247b04ce44"
      },
      "source": [
        "hist = model.fit_generator(\n",
        "    generator=train_generator,  \n",
        "    validation_data=val_generator,\n",
        "    verbose=1, \n",
        "    epochs=num_epochs,\n",
        "    workers=workers,\n",
        "    steps_per_epoch=len(train_generator),\n",
        "    validation_steps=len(val_generator))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "200/200 [==============================] - 1054s 5s/step - loss: 0.7908 - accuracy: 0.5075 - val_loss: 0.6943 - val_accuracy: 0.5000\n",
            "Epoch 2/10\n",
            "200/200 [==============================] - 928s 4s/step - loss: 0.6969 - accuracy: 0.4975 - val_loss: 0.6995 - val_accuracy: 0.5000\n",
            "Epoch 3/10\n",
            "200/200 [==============================] - 947s 4s/step - loss: 0.6992 - accuracy: 0.4900 - val_loss: 0.6938 - val_accuracy: 0.5000\n",
            "Epoch 4/10\n",
            "200/200 [==============================] - 945s 4s/step - loss: 0.6980 - accuracy: 0.4750 - val_loss: 0.6913 - val_accuracy: 0.5000\n",
            "Epoch 5/10\n",
            "200/200 [==============================] - 970s 5s/step - loss: 0.6930 - accuracy: 0.5312 - val_loss: 0.6854 - val_accuracy: 0.5000\n",
            "Epoch 6/10\n",
            "200/200 [==============================] - 1009s 5s/step - loss: 0.6941 - accuracy: 0.5300 - val_loss: 0.6863 - val_accuracy: 0.5800\n",
            "Epoch 7/10\n",
            "200/200 [==============================] - 953s 4s/step - loss: 0.6566 - accuracy: 0.6137 - val_loss: 0.6709 - val_accuracy: 0.5300\n",
            "Epoch 8/10\n",
            "200/200 [==============================] - 951s 4s/step - loss: 0.6359 - accuracy: 0.6388 - val_loss: 0.5441 - val_accuracy: 0.7800\n",
            "Epoch 9/10\n",
            "200/200 [==============================] - 945s 4s/step - loss: 0.6638 - accuracy: 0.6062 - val_loss: 0.6961 - val_accuracy: 0.5000\n",
            "Epoch 10/10\n",
            "200/200 [==============================] - 931s 4s/step - loss: 0.6985 - accuracy: 0.4888 - val_loss: 0.6938 - val_accuracy: 0.5000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DzekNq1SfF4H"
      },
      "source": [
        "Saving Weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMHSl2aVY7hU"
      },
      "source": [
        "model.save('/content/drive/MyDrive/voilence/my_model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYGjlVn7jmgp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "raMCns5ljmdy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BwSA9cUojmbc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CR83GaBhjmZL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Zpgm4uAjmWJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}